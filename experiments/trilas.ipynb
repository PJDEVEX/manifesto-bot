{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_MODEL = os.getenv(\"OPENAI_API_MODEL\")\n",
    "OPENAI_MAX_TOKENS=os.getenv(\"OPENAI_MAX_TOKENS\")\n",
    "OPENAI_TEMPERATURE=os.getenv(\"OPENAI_TEMPERATURE\")\n",
    "EMBEDDING_MODEL_NAME = os.getenv(\"EMBEDDING_MODEL_NAME\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_CLOUD = os.getenv(\"PINECONE_CLOUD\")\n",
    "PINECONE_REGION = os.getenv(\"PINECONE_REGION\")\n",
    "PINECONE_DIMENSION = os.getenv(\"PINECONE_DIMENSION\")\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['OPENAI_API_MODEL'] = OPENAI_API_MODEL\n",
    "os.environ['OPENAI_MAX_TOKENS'] = OPENAI_MAX_TOKENS\n",
    "os.environ['OPENAI_TEMPERATURE'] = OPENAI_TEMPERATURE\n",
    "os.environ['EMBEDDING_MODEL_NAME'] = EMBEDDING_MODEL_NAME\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY  \n",
    "os.environ['PINECONE_INDEX_NAME'] = PINECONE_INDEX_NAME\n",
    "os.environ['PINECONE_CLOUD'] = PINECONE_CLOUD\n",
    "os.environ['PINECONE_REGION'] = PINECONE_REGION\n",
    "os.environ['PINECONE_DIMENSION'] = PINECONE_DIMENSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_docs():\n",
    "    loader = DirectoryLoader(\n",
    "        path=\"../data\",\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "        use_multithreading=True,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call load function to upload the folder\n",
    "for file in os.listdir(\"../data\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        extract_document = get_load_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the extracted data: 105\n"
     ]
    }
   ],
   "source": [
    "print(f'length of the extracted data: {len(extract_document)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of the data extracted: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(f'type of the data extracted: {type(extract_document)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitting and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_splitted_and_chunked(extract_document):\n",
    "  \"\"\"\n",
    "    Split and chunk text into smaller segments.\n",
    "\n",
    "    Parameters:\n",
    "    - extract_document (str): The text document to be split and chunked.\n",
    "\n",
    "    Returns:\n",
    "    - text_chunks (list): A list containing the split and chunked text segments.\n",
    "\n",
    "    Example:\n",
    "    >>> document = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit...\"\n",
    "    >>> chunks = split_and_chunk_text(document)\n",
    "    \"\"\"\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "      chunk_size=100,\n",
    "      chunk_overlap=10,\n",
    "      is_separator_regex=True,\n",
    "  )\n",
    "  text_chunks = text_splitter.split_documents(extract_document)\n",
    "  return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call get_text_splitted_and_chunked function\n",
    "text_chunks = get_text_splitted_and_chunked(extract_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(len(text_chunks[35].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on an urgent basis by a simple amendment to the legislation. We will enact a Public Procurement Law\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print((text_chunks[89].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "  \"\"\"\n",
    "    Initializes and returns an instance of Hugging Face Embeddings.\n",
    "\n",
    "    Returns:\n",
    "    HuggingFaceEmbeddings: An instance of Hugging Face Embeddings \\n\n",
    "    initialized with the specified model name.\n",
    "  \"\"\"\n",
    "  model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "  model_kwargs = {'device': 'cpu'}\n",
    "  encode_kwargs = {'normalize_embeddings': False}\n",
    "  embeddings = HuggingFaceEmbeddings(\n",
    "      model_name=model_name,\n",
    "      model_kwargs=model_kwargs,\n",
    "      encode_kwargs=encode_kwargs\n",
    "  )\n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj/anaconda3/envs/mb/lib/python3.10/site-packages/transformers-4.44.2-py3.10.egg/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calling the get_embeddings function\n",
    "embeddings = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "embedded_query = embeddings.embed_query(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(embedded_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate pinecone vector database and stor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = ServerlessSpec(cloud=PINECONE_CLOUD, region=PINECONE_REGION)\n",
    "\n",
    "index_name = PINECONE_INDEX_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index\n",
    "pc.create_index(\n",
    "    dimension=int(PINECONE_DIMENSION),\n",
    "    name=PINECONE_INDEX_NAME,\n",
    "    metric=\"cosine\",\n",
    "    spec=spec\n",
    ")\n",
    "\n",
    "# Wat for index to be ready before connecting\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "  time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifesto-bot\n"
     ]
    }
   ],
   "source": [
    "print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "query = \"What are the key economic reforms to be introduced by Sajith?\"\n",
    "response = vectorstore.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Tax reforms; (2) Monetary \\npolicy reforms, including \\nCentral Bank (CBSL) \\nindependence; (3) Cost-'),\n",
       " Document(page_content='such as reforming the public sector and state-owned enterprises – is a must. Reforms in energy'),\n",
       " Document(page_content='reforms in ten key areas, as detailed below. \\nThe 10 pillars of reform:\\n01\\n02\\n03\\n04'),\n",
       " Document(page_content='also implementing deep \\nstructural reforms to \\naddress long-standing \\nissues. The SJB’s'),\n",
       " Document(page_content='and (5) Governance \\nreforms.Some Progress: Since \\nstarting the EFF program, \\nthe government has')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=OPENAI_API_MODEL,\n",
    "    max_tokens=OPENAI_MAX_TOKENS,\n",
    "    temperature=OPENAI_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100,\n",
    "    input_key=\"query\",\n",
    "    output_key=\"result\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f89ff4c6dd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f89ff4e5330>, root_client=<openai.OpenAI object at 0x7f89ff4c7130>, root_async_client=<openai.AsyncOpenAI object at 0x7f89ff4c48b0>, temperature=0.2, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an honest, unbiased, and knowledgeable assistant and \\n\n",
    "reviewer who helps voters to assist them in answering critically \\n \n",
    "on the question {question}, they ask based on the manifestos of presidential \\n\n",
    "candidates of the upcoming presidential elections in Sri Lanka. \\n\\n\n",
    "\n",
    "Your answers should be based on the manifestos of the presidential \\n\n",
    "candidates and should not be biased or influenced by any political \\n\n",
    "party or individual. \\n\\n \n",
    "\n",
    "You should provide the complete, concise and answer with high readability \\n\n",
    "score within the given token limit. \\n\\n\n",
    "\n",
    "Context: {context} \\n\\n\n",
    "Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate.from_template(\n",
    "    prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\nYou are an honest, unbiased, and knowledgeable assistant and \\n\\nreviewer who helps voters to assist them in answering critically \\n \\non the question {question}, they ask based on the manifestos of presidential \\n\\ncandidates of the upcoming presidential elections in Sri Lanka. \\n\\n\\n\\nYour answers should be based on the manifestos of the presidential \\n\\ncandidates and should not be biased or influenced by any political \\n\\nparty or individual. \\n\\n \\n\\nYou should provide the complete, concise and answer with high readability \\n\\nscore within the given token limit. \\n\\n\\n\\nContext: {context} \\n\\n\\nResponse:\\n'\n"
     ]
    }
   ],
   "source": [
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "      \"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the key economic reforms to be introduced by Sajith?\"\n",
    "response = rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the manifestos of the presidential candidates in Sri Lanka, key economic reforms to be introduced by Sajith include tax reforms, monetary policy reforms (including Central Bank independence), and reforms in the public sector and state-owned enterprises. Additionally, there is a focus on energy reforms and deep structural reforms to address long-standing issues. The 10 pillars of reform outlined include areas such as improving infrastructure, promoting innovation and technology, enhancing education and skills development, and fostering a conducive environment for businesses. These'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search_with_score(query=question, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tax reforms; (2) Monetary \n",
      "policy reforms, including \n",
      "Central Bank (CBSL) \n",
      "independence; (3) Cost-\n",
      "such as reforming the public sector and state-owned enterprises – is a must. Reforms in energy\n",
      "reforms in ten key areas, as detailed below. \n",
      "The 10 pillars of reform:\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "also implementing deep \n",
      "structural reforms to \n",
      "address long-standing \n",
      "issues. The SJB’s\n"
     ]
    }
   ],
   "source": [
    "for doc, score in results:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.668023467\n",
      "Text Segment: Tax reforms; (2) Monetary \n",
      "policy reforms, including \n",
      "Central Bank (CBSL) \n",
      "independence; (3) Cost-\n",
      "---\n",
      "Score: 0.646106541\n",
      "Text Segment: such as reforming the public sector and state-owned enterprises – is a must. Reforms in energy\n",
      "---\n",
      "Score: 0.638928354\n",
      "Text Segment: reforms in ten key areas, as detailed below. \n",
      "The 10 pillars of reform:\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "---\n",
      "Score: 0.635710835\n",
      "Text Segment: also implementing deep \n",
      "structural reforms to \n",
      "address long-standing \n",
      "issues. The SJB’s\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def similarity_search_with_metadata(vectorstore, question):\n",
    "    # Perform similarity search\n",
    "    results = vectorstore.similarity_search_with_score(query=question, k=4)\n",
    "    \n",
    "    # Display the source and text segment for each result\n",
    "    for doc, score in results:\n",
    "        metadata = doc.page_content  # Adjust according to your document structure\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Text Segment: {metadata}\")\n",
    "        print(\"---\")\n",
    "\n",
    "similarity_search_with_metadata(vectorstore, question=question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
